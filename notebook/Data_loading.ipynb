{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "13ea6c0f",
   "metadata": {},
   "source": [
    "### Data Loading "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3aa09c4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in c:\\users\\wwwsu\\desktop\\all folders\\logistics_demand\\venv\\lib\\site-packages (2.2.3)\n",
      "Requirement already satisfied: numpy in c:\\users\\wwwsu\\desktop\\all folders\\logistics_demand\\venv\\lib\\site-packages (2.2.5)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\wwwsu\\desktop\\all folders\\logistics_demand\\venv\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\wwwsu\\desktop\\all folders\\logistics_demand\\venv\\lib\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\wwwsu\\desktop\\all folders\\logistics_demand\\venv\\lib\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\wwwsu\\desktop\\all folders\\logistics_demand\\venv\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.2.1 -> 25.1.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install pandas numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1240d709",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c2e9eaf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "sales = pd.read_csv(r'C:\\Users\\wwwsu\\Desktop\\All folders\\Logistics_demand\\data\\raw\\sales_train_evaluation.csv')\n",
    "price = pd.read_csv(r'C:\\Users\\wwwsu\\Desktop\\All folders\\Logistics_demand\\data\\raw\\sell_prices.csv')\n",
    "calendar = pd.read_csv(r'C:\\Users\\wwwsu\\Desktop\\All folders\\Logistics_demand\\data\\raw\\calendar.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc31d8f6",
   "metadata": {},
   "source": [
    "### Optimizing Sales dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "508f432c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sales Data Memory Usage (MB): 116.6247148513794\n"
     ]
    }
   ],
   "source": [
    "# Convert identifier columns to category\n",
    "id_cols = ['id', 'item_id', 'dept_id', 'cat_id', 'store_id', 'state_id']\n",
    "for col in id_cols:\n",
    "    sales[col] = sales[col].astype('category')\n",
    "\n",
    "# Convert sales columns to smaller int type (e.g., uint16)\n",
    "sales_cols = sales.columns.difference(id_cols)\n",
    "sales[sales_cols] = sales[sales_cols].astype(np.uint16)\n",
    "\n",
    "# Check memory usage before and after\n",
    "print(\"Sales Data Memory Usage (MB):\", sales.memory_usage(deep=True).sum() / 1024**2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5a463b7",
   "metadata": {},
   "source": [
    "### Optimizing calendar Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "92c2453c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calendar Data Memory Usage (MB): 0.22610950469970703\n"
     ]
    }
   ],
   "source": [
    "# Select essential columns only\n",
    "calendar = calendar[['d', 'date', 'wm_yr_wk', 'weekday', 'wday', 'month', 'year',\n",
    "                     'event_name_1', 'event_type_1', 'event_name_2', 'event_type_2',\n",
    "                     'snap_CA', 'snap_TX', 'snap_WI']]\n",
    "\n",
    "# Convert d to category\n",
    "calendar['d'] = calendar['d'].astype('category')\n",
    "\n",
    "# Convert date to datetime\n",
    "calendar['date'] = pd.to_datetime(calendar['date'])\n",
    "\n",
    "# Convert categorical columns\n",
    "cat_cols = ['weekday', 'event_name_1', 'event_type_1', 'event_name_2', 'event_type_2']\n",
    "for col in cat_cols:\n",
    "    calendar[col] = calendar[col].astype('category')\n",
    "\n",
    "# Convert numeric columns\n",
    "calendar['wday'] = calendar['wday'].astype(np.int8)\n",
    "calendar['month'] = calendar['month'].astype(np.int8)\n",
    "calendar['year'] = calendar['year'].astype(np.int16)\n",
    "calendar['snap_CA'] = calendar['snap_CA'].astype(np.int8)\n",
    "calendar['snap_TX'] = calendar['snap_TX'].astype(np.int8)\n",
    "calendar['snap_WI'] = calendar['snap_WI'].astype(np.int8)\n",
    "\n",
    "print(\"Calendar Data Memory Usage (MB):\", calendar.memory_usage(deep=True).sum() / 1024**2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95a6e057",
   "metadata": {},
   "source": [
    "### Optimize Price Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e3bcf544",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Price Data Memory Usage (MB): 58.96129322052002\n"
     ]
    }
   ],
   "source": [
    "price['store_id'] = price['store_id'].astype('category')\n",
    "price['item_id'] = price['item_id'].astype('category')\n",
    "price['wm_yr_wk'] = price['wm_yr_wk'].astype(np.int16)\n",
    "price['sell_price'] = price['sell_price'].astype(np.float32)\n",
    "\n",
    "print(\"Price Data Memory Usage (MB):\", price.memory_usage(deep=True).sum() / 1024**2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4ef3259",
   "metadata": {},
   "source": [
    "### Cleaning the data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d6fce2a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values in sales data:\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "print(\"Missing values in sales data:\")\n",
    "print(sales.isnull().sum().sum()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4dd6eca6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values in price data:\n",
      "store_id      0\n",
      "item_id       0\n",
      "wm_yr_wk      0\n",
      "sell_price    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"Missing values in price data:\")\n",
    "print(price.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "33ca03ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values in calendar data:\n",
      "d                  0\n",
      "date               0\n",
      "wm_yr_wk           0\n",
      "weekday            0\n",
      "wday               0\n",
      "month              0\n",
      "year               0\n",
      "event_name_1    1807\n",
      "event_type_1    1807\n",
      "event_name_2    1964\n",
      "event_type_2    1964\n",
      "snap_CA            0\n",
      "snap_TX            0\n",
      "snap_WI            0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"Missing values in calendar data:\")\n",
    "print(calendar.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92ec027a",
   "metadata": {},
   "source": [
    "Missing event names/types mean no event on those days, which is expected because most days are normal days without special events. So, these missing values are not errors but represent “no event”."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2866b27",
   "metadata": {},
   "source": [
    "### Filling missing event values with 'No_event'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "976793b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "calendar['event_name_1'] = calendar['event_name_1'].cat.add_categories('No_event').fillna('No_event')\n",
    "calendar['event_type_1'] = calendar['event_type_1'].cat.add_categories('No_event').fillna('No_event')\n",
    "\n",
    "calendar['event_name_2'] = calendar['event_name_2'].cat.add_categories('No_event').fillna('No_event')\n",
    "calendar['event_type_2'] = calendar['event_type_2'].cat.add_categories('No_event').fillna('No_event')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eeae3783",
   "metadata": {},
   "source": [
    "### Analyze Zero Sales Distribution \n",
    "Zero sales days are common and meaningful (e.g., no demand, out-of-stock). Understanding zero sales patterns helps decide if any filtering or special handling is needed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07558f53",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d4249fc7",
   "metadata": {},
   "source": [
    "#### Calculating Percentage of zero sales per item-store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "62e6e473",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\wwwsu\\AppData\\Local\\Temp\\ipykernel_30548\\2898919737.py:10: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  zero_sales_pct = sales_long.groupby(['item_id', 'store_id'])['sales'].apply(lambda x: (x == 0).mean())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count    30490.000000\n",
      "mean         0.679978\n",
      "std          0.223406\n",
      "min          0.001546\n",
      "25%          0.534776\n",
      "50%          0.733127\n",
      "75%          0.865018\n",
      "max          0.993818\n",
      "Name: sales, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Melt sales data to long format for easier analysis\n",
    "sales_long = pd.melt(\n",
    "    sales,\n",
    "    id_vars=['id', 'item_id', 'dept_id', 'cat_id', 'store_id', 'state_id'],\n",
    "    var_name='d',\n",
    "    value_name='sales'\n",
    ")\n",
    "\n",
    "# Calculate zero sales percentage per item-store combination\n",
    "zero_sales_pct = sales_long.groupby(['item_id', 'store_id'])['sales'].apply(lambda x: (x == 0).mean())\n",
    "\n",
    "# Summary statistics of zero sales percentage\n",
    "print(zero_sales_pct.describe())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1864736",
   "metadata": {},
   "source": [
    "Since the median zero sales is 73%, zeros are a significant part of the data and should not be removed blindly."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d1d9a5b",
   "metadata": {},
   "source": [
    "### Merging Datasets and Aggregating Weekly"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4f80e0e",
   "metadata": {},
   "source": [
    "#### Merging sales_long with calender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cd949794",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sales_calendar shape: (59181090, 10)\n",
      "                              id        item_id    dept_id   cat_id store_id  \\\n",
      "0  HOBBIES_1_001_CA_1_evaluation  HOBBIES_1_001  HOBBIES_1  HOBBIES     CA_1   \n",
      "1  HOBBIES_1_002_CA_1_evaluation  HOBBIES_1_002  HOBBIES_1  HOBBIES     CA_1   \n",
      "2  HOBBIES_1_003_CA_1_evaluation  HOBBIES_1_003  HOBBIES_1  HOBBIES     CA_1   \n",
      "3  HOBBIES_1_004_CA_1_evaluation  HOBBIES_1_004  HOBBIES_1  HOBBIES     CA_1   \n",
      "4  HOBBIES_1_005_CA_1_evaluation  HOBBIES_1_005  HOBBIES_1  HOBBIES     CA_1   \n",
      "\n",
      "  state_id    d  sales       date  wm_yr_wk  \n",
      "0       CA  d_1      0 2011-01-29     11101  \n",
      "1       CA  d_1      0 2011-01-29     11101  \n",
      "2       CA  d_1      0 2011-01-29     11101  \n",
      "3       CA  d_1      0 2011-01-29     11101  \n",
      "4       CA  d_1      0 2011-01-29     11101  \n"
     ]
    }
   ],
   "source": [
    "# Merge sales_long with calendar on 'd' to get date and wm_yr_wk\n",
    "sales_calendar = sales_long.merge(calendar[['d', 'date', 'wm_yr_wk']], on='d', how='left')\n",
    "\n",
    "print(f\"sales_calendar shape: {sales_calendar.shape}\")\n",
    "print(sales_calendar.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2a834b7",
   "metadata": {},
   "source": [
    "#### Merging sales_calendar with price "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ebf088ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "full_data shape: (59181090, 11)\n",
      "                              id        item_id    dept_id   cat_id store_id  \\\n",
      "0  HOBBIES_1_001_CA_1_evaluation  HOBBIES_1_001  HOBBIES_1  HOBBIES     CA_1   \n",
      "1  HOBBIES_1_002_CA_1_evaluation  HOBBIES_1_002  HOBBIES_1  HOBBIES     CA_1   \n",
      "2  HOBBIES_1_003_CA_1_evaluation  HOBBIES_1_003  HOBBIES_1  HOBBIES     CA_1   \n",
      "3  HOBBIES_1_004_CA_1_evaluation  HOBBIES_1_004  HOBBIES_1  HOBBIES     CA_1   \n",
      "4  HOBBIES_1_005_CA_1_evaluation  HOBBIES_1_005  HOBBIES_1  HOBBIES     CA_1   \n",
      "\n",
      "  state_id    d  sales       date  wm_yr_wk  sell_price  \n",
      "0       CA  d_1      0 2011-01-29     11101         NaN  \n",
      "1       CA  d_1      0 2011-01-29     11101         NaN  \n",
      "2       CA  d_1      0 2011-01-29     11101         NaN  \n",
      "3       CA  d_1      0 2011-01-29     11101         NaN  \n",
      "4       CA  d_1      0 2011-01-29     11101         NaN  \n"
     ]
    }
   ],
   "source": [
    "# Merge with price on item_id, store_id, and wm_yr_wk\n",
    "full_data = sales_calendar.merge(price, on=['item_id', 'store_id', 'wm_yr_wk'], how='left')\n",
    "\n",
    "print(f\"full_data shape: {full_data.shape}\")\n",
    "print(full_data.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7217b33",
   "metadata": {},
   "source": [
    "#### Aggregating Weekly Sales and Price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "dcd4ea72",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\wwwsu\\AppData\\Local\\Temp\\ipykernel_30548\\3845643553.py:1: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  weekly_data = full_data.groupby(['item_id', 'store_id', 'wm_yr_wk']).agg({\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weekly_data shape: (8476220, 5)\n",
      "       item_id store_id  wm_yr_wk  sales  sell_price\n",
      "0  FOODS_1_001     CA_1     11101     10         2.0\n",
      "1  FOODS_1_001     CA_1     11102      6         2.0\n",
      "2  FOODS_1_001     CA_1     11103     10         2.0\n",
      "3  FOODS_1_001     CA_1     11104     13         2.0\n",
      "4  FOODS_1_001     CA_1     11105     15         2.0\n"
     ]
    }
   ],
   "source": [
    "weekly_data = full_data.groupby(['item_id', 'store_id', 'wm_yr_wk']).agg({\n",
    "    'sales': 'sum',\n",
    "    'sell_price': 'mean'\n",
    "}).reset_index()\n",
    "\n",
    "print(f\"weekly_data shape: {weekly_data.shape}\")\n",
    "print(weekly_data.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e2e40fd",
   "metadata": {},
   "source": [
    "#### Adding calendar Features to weekly data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ad6132a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract unique week info from calendar\n",
    "week_info = calendar[['wm_yr_wk', 'month', 'year']].drop_duplicates()\n",
    "\n",
    "# Merge with weekly_data\n",
    "weekly_data = weekly_data.merge(week_info, on='wm_yr_wk', how='left')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ef2058f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       item_id store_id  wm_yr_wk  sales  sell_price  month  year\n",
      "0  FOODS_1_001     CA_1     11101     10         2.0      1  2011\n",
      "1  FOODS_1_001     CA_1     11101     10         2.0      2  2011\n",
      "2  FOODS_1_001     CA_1     11102      6         2.0      2  2011\n",
      "3  FOODS_1_001     CA_1     11103     10         2.0      2  2011\n",
      "4  FOODS_1_001     CA_1     11104     13         2.0      2  2011\n"
     ]
    }
   ],
   "source": [
    "print(weekly_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ec14b75d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10183660, 7)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weekly_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "913b1e15",
   "metadata": {},
   "outputs": [],
   "source": [
    "weekly_data.to_csv('../data/processed/weekly_aggregated_sales.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
